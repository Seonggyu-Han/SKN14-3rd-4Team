import streamlit as st
import base64
import os
import ast
import threading
from io import BytesIO
from typing import List, Tuple, Dict, Any
import openai
from PIL import Image
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_openai import ChatOpenAI

# inferer.pyì—ì„œ Inferer, OpenAIInferer í´ë˜ìŠ¤
from inferer import Inferer, OpenAIInferer


from dotenv import load_dotenv

load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GYM-PT - ë‹¹ì‹ ë§Œì˜ íŠ¸ë ˆì´ë„ˆ",
    page_icon="ğŸ’ª",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E7D32;
        font-size: 3rem;
        font-weight: bold;
        margin-bottom: 1rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }

    .sub-header {
        text-align: center;
        color: #4CAF50;
        font-size: 1.3rem;
        margin-bottom: 2rem;
        font-weight: 500;
    }

    .description-box {
        background: linear-gradient(135deg, #E8F5E8 0%, #F1F8E9 100%);
        padding: 2rem;
        border-radius: 15px;
        border-left: 5px solid #4CAF50;
        margin: 2rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }

    .description-text {
        color: #2E7D32;
        font-size: 1.1rem;
        line-height: 1.6;
        text-align: center;
    }

    .stButton > button {
        background: linear-gradient(45deg, #4CAF50, #66BB6A);
        color: white;
        border: none;
        padding: 1rem 2rem;
        font-size: 1.2rem;
        font-weight: bold;
        border-radius: 25px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.3);
    }

    .stButton > button:hover {
        background: linear-gradient(45deg, #388E3C, #4CAF50);
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(76, 175, 80, 0.4);
    }

    .feature-box {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #E8F5E8;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        text-align: center;
    }

    .feature-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
    }

    .feature-title {
        color: #2E7D32;
        font-size: 1.2rem;
        font-weight: bold;
        margin-bottom: 0.5rem;
    }

    .feature-text {
        color: #555;
        font-size: 0.9rem;
        line-height: 1.4;
    }

    /* ì±„íŒ… ì „ì²´ ë°°ê²½ */
    .chat-container {
        background: #F8F9FA;
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: 1px solid #E8F5E8;
    }

    /* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .chat-message {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #4CAF50;
        color: #000000 !important;  /* ê²€ì • í…ìŠ¤íŠ¸ */
    }

    .user-message {
        background: #E8F5E8;
        border-left: 4px solid #2E7D32;
        margin-left: 2rem;
    }

    .assistant-message {
        background: white;
        border-left: 4px solid #4CAF50;
        margin-right: 2rem;
    }

    .upload-area {
        background: #F8F9FA;
        border: 2px dashed #4CAF50;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        margin: 1rem 0;
    }

    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #E8F5E8 0%, #F1F8E9 100%);
    }
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'page' not in st.session_state:
    st.session_state.page = 'main'
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'user_info' not in st.session_state:
    st.session_state.user_info = {}


# Inferer í´ë˜ìŠ¤ ì •ì˜
# class Inferer:
#     def image_to_base64(self, image: Image):
#         buffered = BytesIO()
#         image.save(buffered, format="JPEG")
#         return base64.b64encode(buffered.getvalue()).decode()
#
#     @classmethod
#     def to_pil_image(cls, uploaded_file):
#         return Image.open(uploaded_file).convert('RGB')


# class OpenAIInferer(Inferer):
#     def __init__(self, model_id="gpt-4o-mini", temperature=0.0, api_key=None):
#         self.model_id = model_id
#         self.temperature = temperature
#         api_key = api_key if api_key else os.environ.get("OPENAI_API_KEY")
#         self.llm = ChatOpenAI(model=model_id, temperature=temperature, api_key=api_key)
#         self.system_msg = SystemMessage("""
# ë‹¹ì‹ ì€ ì „ ì„¸ê³„ ìŒì‹ë“¤ì„ ëª¨ë‘ ë‹¤ ì•Œê³  ìˆëŠ” ìŒì‹ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
#
# ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì œì‹œí•œ ìŒì‹ ì´ë¯¸ì§€ì˜ ì •í™•í•œ ìŒì‹ëª…ì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
# - ë‹µë³€ì€ ë°˜ë“œì‹œ ë‹¨ë‹µí˜•ì˜ ìŒì‹ëª…ê³¼ ê·¸ ìŒì‹ì— ë“¤ì–´ê°„ ì¬ë£Œ ëª©ë¡ì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
# - ìŒì‹ëª…ê³¼ ì¬ë£Œëª©ë¡ì€ ("ìŒì‹ëª…", "ì¬ë£Œëª©ë¡") ì˜ í˜•íƒœë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
# - ìŒì‹ëª…ê³¼ ì¬ë£Œëª©ë¡ì€ ë°˜ë“œì‹œ í•œê¸€ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
# - ë‹µë³€ì€ [("ìŒì‹ëª…", "ì¬ë£Œëª©ë¡")] ê³¼ ê°™ì´ ë°°ì—´ë¡œ ê°ì‹¼ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
# - ì´ë¯¸ì§€ì— ìŒì‹ì˜ ê°œìˆ˜ê°€ ì—¬ëŸ¬ê°€ì§€ë¼ë©´, ìµœëŒ€ 5ê°œì˜ ìŒì‹ì„ ë°°ì—´ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
#
# < ë‹µë³€ ì˜ˆì‹œ >
# [("ì§œì¥ë©´", "ì¶˜ì¥, ë¼ì§€ê³ ê¸°, ì–‘íŒŒ, ë©´, ì¹´ë¼ë©œ")]
# [("í–„ë²„ê±°", "íŒ¨í‹°, ë²ˆ, ì–‘ìƒì¶”, ì–‘íŒŒ, ë¨¸ìŠ¤íƒ€ë“œì†ŒìŠ¤, ì¹˜ì¦ˆ, í”¼í´"), ("ë² ì´ì»¨ ì—°ì–´ ì…€ëŸ¬ë“œ", "ë² ì´ì»¨, í›ˆì œì—°ì–´, ì–‘ìƒì¶”, í† ë§ˆí† ")]
# """)
#
#     def infer(self, image: Image, filename: str, storage: dict, parser=StrOutputParser()):
#         b64_image = self.image_to_base64(image)
#         user_msg = HumanMessage([{'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{b64_image}'}}])
#         prompt = ChatPromptTemplate.from_messages([self.system_msg, user_msg])
#         chain = prompt | self.llm | parser
#         storage[filename] = chain.invoke({})
#
#     def __call__(self, images: List[Image], filenames: List[str], parser=StrOutputParser()):
#         storage = {}
#         tmp_zip = zip(images, filenames)
#         threads = [threading.Thread(target=self.infer, args=(img, nm, storage, parser)) for img, nm in tmp_zip]
#
#         for thread in threads:
#             thread.start()
#         for thread in threads:
#             thread.join()
#
#         return storage


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def parse_prediction(pred_str: str) -> Tuple[str, str]:
    try:
        parsed = ast.literal_eval(pred_str)
        menu_name, ingredients = parsed[0]
        return menu_name.strip(), ingredients.strip()
    except:
        return pred_str, ""


def ask_llm_calorie(menu_name: str) -> str:
    try:
        prompt = f"ë‹¤ìŒ ìŒì‹ì˜ ëŒ€í‘œì ì¸ 1ì¸ë¶„ ì¹¼ë¡œë¦¬(kcal) ìˆ«ìë§Œ ì•Œë ¤ì£¼ì„¸ìš” **ë°˜ë“œì‹œ ìˆ«ìë§Œ ë°˜í™˜!!**: '{menu_name}'"
        resp = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return resp.choices[0].message.content.strip()
    except:
        return "250"  # ê¸°ë³¸ê°’


def analyze_meal_with_llm(menu_name: str, calorie: str, user_info: str, chat_history=None) -> str:
    try:
        llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.3)
        history_prompt = ""
        if chat_history:
            # ìµœê·¼ 5í„´ contextë§Œ
            for i, (role, content, images) in enumerate(chat_history[-5:]):
                who = "ì‚¬ìš©ì" if role == "user" else "GYM-PT"
                history_prompt += f"{who}: {content}\n"

        prompt = f"""
ì•„ë˜ëŠ” ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ì—­ì…ë‹ˆë‹¤.
{history_prompt}

---
ì‚¬ìš©ìì˜ ìƒˆë¡œìš´ ì…ë ¥ê³¼ ìŒì‹ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì´ì „ ëŒ€í™” ë§¥ë½ë„ ë°˜ì˜í•´ ë§ì¶¤í˜• ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

ë©”ë‰´ëª…: {menu_name}
ì¹¼ë¡œë¦¬: {calorie}kcal
ì‚¬ìš©ì ì •ë³´: {user_info}

[ë‹µë³€ í˜•ì‹]
- ë“œì‹  ë©”ë‰´ì™€ ì¹¼ë¡œë¦¬ ì •ë³´
- 1ì¼ ê¶Œì¥ ì„­ì·¨ëŸ‰ ê³„ì‚°
- í•´ë‹¹ ì¹¼ë¡œë¦¬ë¥¼ ì†Œëª¨í•  ìˆ˜ ìˆëŠ” ìš´ë™ ì¶”ì²œ
- ë‚¨ì€ ì¹¼ë¡œë¦¬ì— ë§ëŠ” ì‹ë‹¨ ì¶”ì²œ

ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        result = llm.invoke(prompt)
        return result.content
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ë©”ì¸ í˜ì´ì§€
def main_page():
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ’ª GYM-PT</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ì‹ë‹¨ê³¼ ìš´ë™ì„ ê´€ë¦¬í•´ì£¼ëŠ” ë‹¹ì‹ ë§Œì˜ íŠ¸ë ˆì´ë„ˆ</p>', unsafe_allow_html=True)

    # ë©”ì¸ ì„¤ëª…
    st.markdown("""
    <div class="description-box">
        <div class="description-text">
            <strong>ğŸ ì˜¤ëŠ˜ ì„­ì·¨í•œ ìŒì‹ì˜ ì‚¬ì§„ë“¤ê³¼ ì•½ê°„ì˜ ì‹ ì²´ì •ë³´ë¥¼ ë„£ì–´ì£¼ì‹œë©´</strong><br><br>
            âœ… ì´ ìŒì‹ì€ ëª‡ ì¹¼ë¡œë¦¬ì¸ì§€<br>
            âœ… ì´ ì¹¼ë¡œë¦¬ë¥¼ ì†Œëª¨í•˜ë ¤ë©´ ì–´ë–¤ ìš´ë™ì„ ì–¼ë§Œí¼ í•´ì•¼í•˜ëŠ”ì§€<br>
            âœ… ë‚¨ì€ ë¼ë‹ˆëŠ” ì–´ë–¤ ìŒì‹ì„ ì„­ì·¨í•˜ë©´ ì¢‹ì„ì§€<br><br>
            <strong>ì „ë¬¸ì ìœ¼ë¡œ ì•Œë ¤ë“œë¦´ê²Œìš”!</strong>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # ê¸°ëŠ¥ ì†Œê°œ
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div class="feature-box">
            <div class="feature-icon">ğŸ“¸</div>
            <div class="feature-title">ì´ë¯¸ì§€ ë¶„ì„</div>
            <div class="feature-text">ìŒì‹ ì‚¬ì§„ì„ ì˜¬ë¦¬ë©´ AIê°€ ë©”ë‰´ì™€ ì¹¼ë¡œë¦¬ë¥¼ ë¶„ì„í•´ë“œë ¤ìš”</div>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="feature-box">
            <div class="feature-icon">ğŸƒâ€â™‚ï¸</div>
            <div class="feature-title">ìš´ë™ ì¶”ì²œ</div>
            <div class="feature-text">ì„­ì·¨í•œ ì¹¼ë¡œë¦¬ì— ë§ëŠ” ë§ì¶¤í˜• ìš´ë™ ê³„íšì„ ì œê³µí•´ë“œë ¤ìš”</div>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="feature-box">
            <div class="feature-icon">ğŸ¥—</div>
            <div class="feature-title">ì‹ë‹¨ ê´€ë¦¬</div>
            <div class="feature-text">ë‚¨ì€ ì¹¼ë¡œë¦¬ì— ë§ëŠ” ê±´ê°•í•œ ì‹ë‹¨ì„ ì¶”ì²œí•´ë“œë ¤ìš”</div>
        </div>
        """, unsafe_allow_html=True)

    # ì‹œì‘ ë²„íŠ¼
    st.markdown("<br><br>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ğŸ½ï¸ ì˜¤ëŠ˜ì˜ ì‹ì‚¬ ì…ë ¥í•˜ê¸°", use_container_width=True):
            st.session_state.page = 'chat'
            st.rerun()


# ë©€í‹°í„´ ì±—ë´‡: chat_historyë¥¼ LLM contextë¡œ ë„£ì–´ì¤Œ!
def chat_page():
    st.markdown('<h2 style="text-align: center; color: #2E7D32; margin-bottom: 2rem;">ğŸ’¬ GYM-PTì™€ ëŒ€í™”í•˜ê¸°</h2>',
                unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 6, 1])
    with col1:
        if st.button("â† ë©”ì¸ìœ¼ë¡œ"):
            st.session_state.page = 'main'
            st.rerun()
    chat_container = st.container()
    with chat_container:
        # st.markdown('<div class="chat-container">', unsafe_allow_html=True)   # ì´ ì¤„ ì‚­ì œ
        if st.session_state.chat_history:
            for i, (role, content, images) in enumerate(st.session_state.chat_history):
                if role == "user":
                    st.markdown(f"""
                    <div class="chat-message user-message">
                        <strong>:bust_in_silhouette: ì‚¬ìš©ì:</strong><br>
                        {content}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="chat-message assistant-message">
                        <strong>:robot: GYM-PT:</strong><br>
                        {content}
                    </div>
                    """, unsafe_allow_html=True)
        # st.markdown('</div>', unsafe_allow_html=True)  # ì´ ì¤„ ì‚­ì œ
    st.markdown("---")
    st.markdown("### ğŸ“ ìƒˆë¡œìš´ ë©”ì‹œì§€")
    uploaded_files = st.file_uploader(
        "ìŒì‹ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš” (ìµœëŒ€ 5ê°œ)",
        type=['png', 'jpg', 'jpeg'],
        accept_multiple_files=True,
        help="ì„­ì·¨í•œ ìŒì‹ì˜ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”. ìµœëŒ€ 5ê°œê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )
    if uploaded_files and len(uploaded_files) > 5:
        st.error("ìµœëŒ€ 5ê°œì˜ ì´ë¯¸ì§€ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        uploaded_files = uploaded_files[:5]
    user_text = st.text_area(
        "ì‹ ì²´ ì •ë³´ì™€ ìŒì‹ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”",
        placeholder="ì˜ˆ: ë‚˜ì´ 25ì„¸, ë‚¨ì„±, í‚¤ 175cm, ëª¸ë¬´ê²Œ 70kg, í‰ì†Œ ìš´ë™ëŸ‰ ì¤‘ê°„, ì•„ì¹¨ì— ì‚¶ì€ ê³„ë€ 2ê°œ ë¨¹ìŒ....",
        height=100
    )
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ğŸ“¤ ë¶„ì„ ìš”ì²­í•˜ê¸°", use_container_width=True):
            if not uploaded_files and not user_text:
                st.error("ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ëŠ” ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        user_images = []
                        if uploaded_files:
                            for uploaded_file in uploaded_files:
                                img = Image.open(uploaded_file)
                                user_images.append(img)
                        st.session_state.chat_history.append(("user", user_text, user_images))
                        if uploaded_files:
                            os.environ.setdefault("OPENAI_API_KEY", "your-api-key-here")
                            inferer = OpenAIInferer("gpt-4o-mini", 0.0)
                            images = [Inferer.to_pil_image(f) for f in uploaded_files]
                            filenames = [f.name for f in uploaded_files]
                            try:
                                results = inferer(images, filenames)
                                response_parts = []
                                for filename, pred_str in results.items():
                                    menu_name, ingredients = parse_prediction(pred_str)
                                    calorie = ask_llm_calorie(menu_name)
                                    # chat_history context ì¶”ê°€!
                                    analysis = analyze_meal_with_llm(
                                        menu_name, calorie, user_text,
                                        chat_history=st.session_state.chat_history
                                    )
                                    response_parts.append(f"ğŸ“¸ **{filename}**\n{analysis}")
                                final_response = "\n\n---\n\n".join(response_parts)
                            except Exception as e:
                                final_response = f"""
ğŸ **ë¶„ì„ ê²°ê³¼ (Demo)**

ë“œì‹  ë©”ë‰´ëŠ” ëŒ€ëµ **600kcal** ì •ë„ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.

ğŸ“Š **ê¶Œì¥ ì„­ì·¨ëŸ‰ ë¶„ì„:**
- ì…ë ¥í•˜ì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ì¼ ê¶Œì¥ ì„­ì·¨ëŸ‰ì€ ì•½ 2,200kcalì…ë‹ˆë‹¤.
- í˜„ì¬ ì„­ì·¨ëŸ‰ì„ ì œì™¸í•˜ë©´ ì•½ 1,600kcalê°€ ë‚¨ì•˜ìŠµë‹ˆë‹¤.

ğŸƒâ€â™‚ï¸ **ì¹¼ë¡œë¦¬ ì†Œëª¨ ìš´ë™:**
- ë¹ ë¥¸ ê±·ê¸°: 90ë¶„ (600kcal ì†Œëª¨)
- ìì „ê±° íƒ€ê¸°: 60ë¶„ (600kcal ì†Œëª¨)
- ì¡°ê¹…: 45ë¶„ (600kcal ì†Œëª¨)

ğŸ¥— **ì¶”ì²œ ì‹ë‹¨:**
- ë‹­ê°€ìŠ´ì‚´ ìƒëŸ¬ë“œ (300kcal)
- í˜„ë¯¸ë°¥ 1ê³µê¸° (280kcal)
- ê³ êµ¬ë§ˆ (200kcal)
- ë‘ë¶€ìš”ë¦¬ (150kcal)

ê±´ê°•í•œ ì‹ë‹¨ ê´€ë¦¬ë¥¼ ìœ„í•´ ê· í˜•ì¡íŒ ì˜ì–‘ì†Œ ì„­ì·¨ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤! ğŸ’ª

*ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.*
"""
                        else:
                            # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ë©€í‹°í„´ context í™œìš©!
                            final_response = analyze_meal_with_llm(
                                menu_name="", calorie="", user_info=user_text,
                                chat_history=st.session_state.chat_history
                            )
                        st.session_state.chat_history.append(("assistant", final_response, None))
                        st.rerun()
                    except Exception as e:
                        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


# ë©”ì¸ ì•± ì‹¤í–‰
def main():
    if st.session_state.page == 'main':
        main_page()
    elif st.session_state.page == 'chat':
        chat_page()


if __name__ == "__main__":
    main()

