import streamlit as st
from inferer import *
from util import *
from config import *

# ë©€í‹°í„´ ì±—ë´‡: chat_historyë¥¼ LLM contextë¡œ ë„£ì–´ì¤Œ!
def chat_page():
    session_initiate()
    print_session_state()

    st.markdown('<h2 style="text-align: center; color: #2E7D32; margin-bottom: 2rem;">ğŸ’¬ GYM-PTì™€ ëŒ€í™”í•˜ê¸°</h2>', unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 6, 1])
    with col1:
        if st.button("â† ë©”ì¸ìœ¼ë¡œ"):
            st.session_state.page = 'main'
            st.rerun()
    chat_container = st.container()
    with chat_container:
        # st.markdown('<div class="chat-container">', unsafe_allow_html=True)   # ì´ ì¤„ ì‚­ì œ
        if st.session_state.chat_history:
            for i, (role, content, images) in enumerate(st.session_state.chat_history):
                if role == "user":
                    st.markdown(f"""
                    <div class="chat-message user-message">
                        <strong>ğŸ‘¤ ì‚¬ìš©ì:</strong><br>
                        {content}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="chat-message assistant-message">
                        <strong>ğŸ¤– GYM-PT:</strong><br>
                        {content}
                    </div>
                    """, unsafe_allow_html=True)
        # st.markdown('</div>', unsafe_allow_html=True)  # ì´ ì¤„ ì‚­ì œ

    st.markdown("---")
    st.markdown("### ğŸ“ ìƒˆë¡œìš´ ë©”ì‹œì§€")
    uploaded_files = st.file_uploader(
        "ìŒì‹ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš” (ìµœëŒ€ 5ê°œ)",
        type=['png', 'jpg', 'jpeg'],
        accept_multiple_files=True,
        help="ì„­ì·¨í•œ ìŒì‹ì˜ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”. ìµœëŒ€ 5ê°œê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )
    if uploaded_files and len(uploaded_files) > 5:
        st.error("ìµœëŒ€ 5ê°œì˜ ì´ë¯¸ì§€ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        uploaded_files = uploaded_files[:5]
    user_text = st.text_area(
        "ì‹ ì²´ ì •ë³´ì™€ ìŒì‹ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”",
        placeholder="ì˜ˆ: ë‚˜ì´ 25ì„¸, ë‚¨ì„±, í‚¤ 175cm, ëª¸ë¬´ê²Œ 70kg, í‰ì†Œ ìš´ë™ëŸ‰ ì¤‘ê°„, ì•„ì¹¨ì— ì‚¶ì€ ê³„ë€ 2ê°œ ë¨¹ìŒ....",
        height=100
    )
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ğŸ“¤ ë¶„ì„ ìš”ì²­í•˜ê¸°", use_container_width=True):
            if not uploaded_files and not user_text:
                st.error("ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ëŠ” ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        user_images = []
                        if uploaded_files:
                            for uploaded_file in uploaded_files:
                                img = Image.open(uploaded_file)
                                user_images.append(img)
                        st.session_state.chat_history.append(("user", user_text, user_images))
                        if uploaded_files:
                            os.environ.setdefault("OPENAI_API_KEY", "your-api-key-here")
                            inferer = OpenAIInferer("gpt-4o-mini", 0.0)
                            images = [Inferer.to_pil_image(f) for f in uploaded_files]
                            filenames = [f.name for f in uploaded_files]
                            try:
                                results = inferer(images, filenames)
                                response_parts = []
                                for filename, pred_str in results.items():
                                    menu_name, ingredients = parse_prediction(pred_str)
                                    rag_context, calorie = get_menu_context_with_threshold(menu_name)
                                    analysis = analyze_meal_with_llm(
                                        menu_name, calorie, user_text,
                                        chat_history=st.session_state.chat_history
                                    )
                                    response_parts.append(f"ğŸ“¸ **{filename}**\n{rag_context}\n\n{analysis}")

                                final_response = "\n\n---\n\n".join(response_parts)
                            except Exception as e:
                                final_response = f"""
ğŸ **ë¶„ì„ ê²°ê³¼ (Demo)**

ë“œì‹  ë©”ë‰´ëŠ” ëŒ€ëµ **600kcal** ì •ë„ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.

ğŸ“Š **ê¶Œì¥ ì„­ì·¨ëŸ‰ ë¶„ì„:**
- ì…ë ¥í•˜ì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ì¼ ê¶Œì¥ ì„­ì·¨ëŸ‰ì€ ì•½ 2,200kcalì…ë‹ˆë‹¤.
- í˜„ì¬ ì„­ì·¨ëŸ‰ì„ ì œì™¸í•˜ë©´ ì•½ 1,600kcalê°€ ë‚¨ì•˜ìŠµë‹ˆë‹¤.

ğŸƒâ€â™‚ï¸ **ì¹¼ë¡œë¦¬ ì†Œëª¨ ìš´ë™:**
- ë¹ ë¥¸ ê±·ê¸°: 90ë¶„ (600kcal ì†Œëª¨)
- ìì „ê±° íƒ€ê¸°: 60ë¶„ (600kcal ì†Œëª¨)
- ì¡°ê¹…: 45ë¶„ (600kcal ì†Œëª¨)

ğŸ¥— **ì¶”ì²œ ì‹ë‹¨:**
- ë‹­ê°€ìŠ´ì‚´ ìƒëŸ¬ë“œ (300kcal)
- í˜„ë¯¸ë°¥ 1ê³µê¸° (280kcal)
- ê³ êµ¬ë§ˆ (200kcal)
- ë‘ë¶€ìš”ë¦¬ (150kcal)

ê±´ê°•í•œ ì‹ë‹¨ ê´€ë¦¬ë¥¼ ìœ„í•´ ê· í˜•ì¡íŒ ì˜ì–‘ì†Œ ì„­ì·¨ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤! ğŸ’ª

*ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.*
"""
                        else:
                            # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ë©€í‹°í„´ context í™œìš©!
                            final_response = analyze_meal_with_llm(
                                menu_name="", calorie="", user_info=user_text,
                                chat_history=st.session_state.chat_history
                            )
                        st.session_state.chat_history.append(("assistant", final_response, None))
                        st.rerun()
                    except Exception as e:
                        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")