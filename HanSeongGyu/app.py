import streamlit as st
import base64
import os
import ast
import threading
from io import BytesIO
from typing import List, Tuple, Dict, Any
import openai
from PIL import Image
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone
import dotenv

dotenv.load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GYM-PT - ë‹¹ì‹ ë§Œì˜ íŠ¸ë ˆì´ë„ˆ",
    page_icon="ğŸ’ª",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- ì…ë ¥ê°’ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'user_text' not in st.session_state:
    st.session_state.user_text = ''
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = None

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E7D32;
        font-size: 3rem;
        font-weight: bold;
        margin-bottom: 1rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .sub-header {
        text-align: center;
        color: #4CAF50;
        font-size: 1.3rem;
        margin-bottom: 2rem;
        font-weight: 500;
    }
    
    .description-box {
        background: linear-gradient(135deg, #E8F5E8 0%, #F1F8E9 100%);
        padding: 2rem;
        border-radius: 15px;
        border-left: 5px solid #4CAF50;
        margin: 2rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .description-text {
        color: #2E7D32;
        font-size: 1.1rem;
        line-height: 1.6;
        text-align: center;
    }
    
    .stButton > button {
        background: linear-gradient(45deg, #4CAF50, #66BB6A);
        color: white;
        border: none;
        padding: 1rem 2rem;
        font-size: 1.2rem;
        font-weight: bold;
        border-radius: 25px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(76, 175, 80, 0.3);
    }
    
    .stButton > button:hover {
        background: linear-gradient(45deg, #388E3C, #4CAF50);
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(76, 175, 80, 0.4);
    }
    
    .feature-box {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #E8F5E8;
        margin: 1rem 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        text-align: center;
    }
    
    .feature-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
    }
    
    .feature-title {
        color: #2E7D32;
        font-size: 1.2rem;
        font-weight: bold;
        margin-bottom: 0.5rem;
    }
    
    .feature-text {
        color: #555;
        font-size: 0.9rem;
        line-height: 1.4;
    }
    
    /* ì±„íŒ… ì „ì²´ ë°°ê²½ */
    .chat-container {
        background: #F8F9FA;
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: 1px solid #E8F5E8;
    }
    
    /* ì±„íŒ… ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .chat-message {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #4CAF50;
        color: #000000 !important;  /* ê²€ì • í…ìŠ¤íŠ¸ */
    }
    
    .user-message {
        background: #E8F5E8;
        border-left: 4px solid #2E7D32;
        margin-left: 2rem;
    }
    
    .assistant-message {
        background: white;
        border-left: 4px solid #4CAF50;
        margin-right: 2rem;
    }
    
    .upload-area {
        background: #F8F9FA;
        border: 2px dashed #4CAF50;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        margin: 1rem 0;
    }
    
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #E8F5E8 0%, #F1F8E9 100%);
    }
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'page' not in st.session_state:
    st.session_state.page = 'main'
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'user_info' not in st.session_state:
    st.session_state.user_info = {}

# Inferer í´ë˜ìŠ¤ ì •ì˜
class Inferer:
    def image_to_base64(self, image: Image):
        buffered = BytesIO()
        image.save(buffered, format="JPEG")
        return base64.b64encode(buffered.getvalue()).decode()

    @classmethod
    def to_pil_image(cls, uploaded_file):
        return Image.open(uploaded_file).convert('RGB')


class OpenAIInferer(Inferer):
    def __init__(self, model_id="gpt-4o-mini", temperature=0.0, api_key=None):
        self.model_id = model_id
        self.temperature = temperature
        api_key = api_key if api_key else os.environ.get("OPENAI_API_KEY")
        self.llm = ChatOpenAI(model=model_id, temperature=temperature, api_key=api_key)
        self.system_msg = SystemMessage("""
ë‹¹ì‹ ì€ ì „ ì„¸ê³„ ìŒì‹ë“¤ì„ ëª¨ë‘ ë‹¤ ì•Œê³  ìˆëŠ” ìŒì‹ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì œì‹œí•œ ìŒì‹ ì´ë¯¸ì§€ì˜ ì •í™•í•œ ìŒì‹ëª…ì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
- ë‹µë³€ì€ ë°˜ë“œì‹œ ë‹¨ë‹µí˜•ì˜ ìŒì‹ëª…ê³¼ ê·¸ ìŒì‹ì— ë“¤ì–´ê°„ ì¬ë£Œ ëª©ë¡ì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
- ìŒì‹ëª…ê³¼ ì¬ë£Œëª©ë¡ì€ ("ìŒì‹ëª…", "ì¬ë£Œëª©ë¡") ì˜ í˜•íƒœë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
- ìŒì‹ëª…ê³¼ ì¬ë£Œëª©ë¡ì€ ë°˜ë“œì‹œ í•œê¸€ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- ë‹µë³€ì€ [("ìŒì‹ëª…", "ì¬ë£Œëª©ë¡")] ê³¼ ê°™ì´ ë°°ì—´ë¡œ ê°ì‹¼ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
- ì´ë¯¸ì§€ì— ìŒì‹ì˜ ê°œìˆ˜ê°€ ì—¬ëŸ¬ê°€ì§€ë¼ë©´, ìµœëŒ€ 5ê°œì˜ ìŒì‹ì„ ë°°ì—´ë¡œ ê°ì‹¸ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.

< ë‹µë³€ ì˜ˆì‹œ >
[("ì§œì¥ë©´", "ì¶˜ì¥, ë¼ì§€ê³ ê¸°, ì–‘íŒŒ, ë©´, ì¹´ë¼ë©œ")]
[("í–„ë²„ê±°", "íŒ¨í‹°, ë²ˆ, ì–‘ìƒì¶”, ì–‘íŒŒ, ë¨¸ìŠ¤íƒ€ë“œì†ŒìŠ¤, ì¹˜ì¦ˆ, í”¼í´"), ("ë² ì´ì»¨ ì—°ì–´ ì…€ëŸ¬ë“œ", "ë² ì´ì»¨, í›ˆì œì—°ì–´, ì–‘ìƒì¶”, í† ë§ˆí† ")]
""")

    def infer(self, image: Image, filename: str, storage: dict, parser=StrOutputParser()):
        b64_image = self.image_to_base64(image)
        user_msg = HumanMessage([{'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{b64_image}'}}])
        prompt = ChatPromptTemplate.from_messages([self.system_msg, user_msg])
        chain = prompt | self.llm | parser
        storage[filename] = chain.invoke({})

    def __call__(self, images: List[Image], filenames: List[str], parser=StrOutputParser()):
        storage = {}
        tmp_zip = zip(images, filenames)
        threads = [threading.Thread(target=self.infer, args=(img, nm, storage, parser)) for img, nm in tmp_zip]
        
        for thread in threads:
            thread.start()
        for thread in threads:
            thread.join()
        
        return storage

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤


PINECONE_PJ_KEY = os.environ.get("PINECONE_PJ_KEY")
INDEX_NAME = "food-index"
EMBED_MODEL = "text-embedding-3-small"
pc = Pinecone(api_key=PINECONE_PJ_KEY)
index = pc.Index(INDEX_NAME)
embeddings = OpenAIEmbeddings(model=EMBED_MODEL)
vector_store = PineconeVectorStore(index=index, embedding=embeddings)


def parse_prediction(pred_str: str) -> Tuple[str, str]:
    try:
        parsed = ast.literal_eval(pred_str)
        menu_name, ingredients = parsed[0]
        return menu_name.strip(), ingredients.strip()
    except:
        return pred_str, ""

# --- 3. Pinecone ê²€ìƒ‰ ---
def search_menu(menu_name: str, k: int = 3) -> List[Tuple]:
    return vector_store.similarity_search_with_score(query=menu_name, k=k)

# --- 4. Pinecone ê²°ê³¼ â†’ ì»¨í…ìŠ¤íŠ¸ í˜•ì‹ ë³€í™˜ ---
def build_context(matches: List[Tuple]) -> str:
    lines = []
    for doc, score in matches:
        meta = doc.metadata or {}
        name = meta.get("RCP_NM", "ì•Œ ìˆ˜ ì—†ëŠ” ë©”ë‰´")
        kcal = meta.get("INFO_ENG", "ì¹¼ë¡œë¦¬ ì •ë³´ ì—†ìŒ")
        lines.append(f"- ë©”ë‰´ëª…: {name}, ì¹¼ë¡œë¦¬: {kcal} (ìœ ì‚¬ë„: {score:.2f})")
    return "\n".join(lines)


def ask_llm_calorie(menu_name: str) -> str:
    try:
        prompt = f"ë‹¤ìŒ ìŒì‹ì˜ ëŒ€í‘œì ì¸ 1ì¸ë¶„ ì¹¼ë¡œë¦¬(kcal) ìˆ«ìë§Œ ì•Œë ¤ì£¼ì„¸ìš” **ë°˜ë“œì‹œ ìˆ«ìë§Œ ë°˜í™˜!!**: '{menu_name}'"
        resp = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        return resp.choices[0].message.content.strip()
    except:
        return "250"  # ê¸°ë³¸ê°’


# --- 6. ë©”ë‰´ëª… ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ìƒì„± + ì¹¼ë¡œë¦¬ ë°˜í™˜ ê°œì„  ë²„ì „ ---
def get_menu_context_with_threshold(
    menu_name: str,
    k: int = 1,
    threshold: float = 0.4
) -> Tuple[str, str]:
    matches = search_menu(menu_name, k)
    
    if not matches or matches[0][1] < threshold:
        # ìœ ì‚¬ë„ ë‚®ì„ ê²½ìš° LLMìœ¼ë¡œ fallback
        calorie = ask_llm_calorie(menu_name)
        context = f"- ë©”ë‰´ëª…: {menu_name}, ì¹¼ë¡œë¦¬: {calorie}"
        return context, calorie

    # ìœ ì‚¬í•œ ë¬¸ì„œê°€ ì¶©ë¶„í•¨ â†’ ë¬¸ì„œì—ì„œ kcal ì¶”ì¶œ
    context = build_context(matches)
    # ê°€ì¥ ì²« ë²ˆì§¸ ë¬¸ì„œ ì •ë³´ ì‚¬ìš©
    doc, _ = matches[0]
    calorie = doc.metadata.get("INFO_ENG")

    # ì¹¼ë¡œë¦¬ ì •ë³´ê°€ ëˆ„ë½ë˜ì–´ ìˆì„ ê²½ìš° fallback
    if not calorie or not str(calorie).isdigit():
        calorie = ask_llm_calorie(menu_name)

    return context, calorie

def analyze_meal_with_llm(menu_infos, user_info, rag_context=None, chat_history=None) -> str:
    try:
        llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.3)
        history_prompt = ""
        if chat_history:
            for i, (role, content, images) in enumerate(chat_history[-5:]):
                who = "ì‚¬ìš©ì" if role == "user" else "GYM-PT"
                history_prompt += f"{who}: {content}\n"

        # ì—¬ëŸ¬ ìŒì‹ ì •ë³´ í‘œì™€ ìš”ì•½ ë§Œë“¤ê¸°
        table = "| No | íŒŒì¼ëª… | ìŒì‹ëª… | ì¹¼ë¡œë¦¬ |\n|---|---|---|---|\n"
        foods_context = ""
        total_calorie = 0
        for i, info in enumerate(menu_infos):
            menu = info.get("menu_name", "")
            kcal = info.get("calorie", "")
            filename = info.get("filename", "")
            table += f"| {i+1} | {filename} | {menu} | {kcal} |\n"
            foods_context += f"{i+1}. {filename}: {menu} ({kcal}kcal)\n"
            try:
                total_calorie += int(float(kcal))
            except:
                pass

        prompt = f"""
[ì˜¤ëŠ˜ ì„­ì·¨í•œ ìŒì‹ ì •ë³´]
{foods_context}
{table}
ì´ ì„­ì·¨ ì¹¼ë¡œë¦¬: {total_calorie}kcal

ì•„ë˜ëŠ” ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ì—­ì…ë‹ˆë‹¤.
{history_prompt}

ì‚¬ìš©ì ì •ë³´: {user_info}

[ë‹µë³€ ì§€ì¹¨]
- ë¨¹ì€ ìŒì‹(ì—¬ëŸ¬ ê°œë©´ ëª¨ë‘)(ì´ë¯¸ì§€ë¡œ ë°›ì€ ìŒì‹ê³¼, í…ìŠ¤íŠ¸ë¡œ ë°›ì€ ì •ë³´ì˜ ìŒì‹ ëª¨ë‘)ê³¼ ê°ê°ì˜ ì¹¼ë¡œë¦¬ ì •ë³´ë¥¼ í‘œë¡œ ë³´ì—¬ì¤„ ê²ƒ
- ëª¨ë“  ìŒì‹ì˜ ì´ ì„­ì·¨ ì¹¼ë¡œë¦¬ë¥¼ ê³„ì‚°í•´ì„œ ë³´ì—¬ì¤„ ê²ƒ
- 1ì¼ ê¶Œì¥ ì„­ì·¨ëŸ‰ê³¼ ë‚¨ì€ ì¹¼ë¡œë¦¬ ê³„ì‚°
- ì‚¬ìš©ìê°€ ì„­ì·¨í•œ ì¹¼ë¡œë¦¬ë¥¼ ì†Œëª¨í•  ìˆ˜ ìˆëŠ” ìš´ë™ ì¶”ì²œ (ì¶”ì²œ ìš´ë™ì˜ ì¹¼ë¡œë¦¬ í•© = ì´ ì„­ì·¨ ì¹¼ë¡œë¦¬)
- ë‚¨ì€ ì¹¼ë¡œë¦¬ì— ë§ëŠ” ì‹ë‹¨ ì¶”ì²œ
- ëª¨ë“  ë‹µë³€ì€ í•œ ë²ˆì—, ë³´ê¸° ì¢‹ê²Œ ì‘ì„±í•  ê²ƒ
"""
        result = llm.invoke(prompt)
        return result.content
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"



# ë©”ì¸ í˜ì´ì§€
def main_page():
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ’ª GYM-PT</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ì‹ë‹¨ê³¼ ìš´ë™ì„ ê´€ë¦¬í•´ì£¼ëŠ” ë‹¹ì‹ ë§Œì˜ íŠ¸ë ˆì´ë„ˆ</p>', unsafe_allow_html=True)
    
    # ë©”ì¸ ì„¤ëª…
    st.markdown("""
    <div class="description-box">
        <div class="description-text">
            <strong>ğŸ ì˜¤ëŠ˜ ì„­ì·¨í•œ ìŒì‹ì˜ ì‚¬ì§„ë“¤ê³¼ ì•½ê°„ì˜ ì‹ ì²´ì •ë³´ë¥¼ ë„£ì–´ì£¼ì‹œë©´</strong><br><br>
            âœ… ì´ ìŒì‹ì€ ëª‡ ì¹¼ë¡œë¦¬ì¸ì§€<br>
            âœ… ì´ ì¹¼ë¡œë¦¬ë¥¼ ì†Œëª¨í•˜ë ¤ë©´ ì–´ë–¤ ìš´ë™ì„ ì–¼ë§Œí¼ í•´ì•¼í•˜ëŠ”ì§€<br>
            âœ… ë‚¨ì€ ë¼ë‹ˆëŠ” ì–´ë–¤ ìŒì‹ì„ ì„­ì·¨í•˜ë©´ ì¢‹ì„ì§€<br><br>
            <strong>ì „ë¬¸ì ìœ¼ë¡œ ì•Œë ¤ë“œë¦´ê²Œìš”!</strong>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # ê¸°ëŠ¥ ì†Œê°œ
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="feature-box">
            <div class="feature-icon">ğŸ“¸</div>
            <div class="feature-title">ì´ë¯¸ì§€ ë¶„ì„</div>
            <div class="feature-text">ìŒì‹ ì‚¬ì§„ì„ ì˜¬ë¦¬ë©´ AIê°€ ë©”ë‰´ì™€ ì¹¼ë¡œë¦¬ë¥¼ ë¶„ì„í•´ë“œë ¤ìš”</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="feature-box">
            <div class="feature-icon">ğŸƒâ€â™‚ï¸</div>
            <div class="feature-title">ìš´ë™ ì¶”ì²œ</div>
            <div class="feature-text">ì„­ì·¨í•œ ì¹¼ë¡œë¦¬ì— ë§ëŠ” ë§ì¶¤í˜• ìš´ë™ ê³„íšì„ ì œê³µí•´ë“œë ¤ìš”</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="feature-box">
            <div class="feature-icon">ğŸ¥—</div>
            <div class="feature-title">ì‹ë‹¨ ê´€ë¦¬</div>
            <div class="feature-text">ë‚¨ì€ ì¹¼ë¡œë¦¬ì— ë§ëŠ” ê±´ê°•í•œ ì‹ë‹¨ì„ ì¶”ì²œí•´ë“œë ¤ìš”</div>
        </div>
        """, unsafe_allow_html=True)
    
    # ì‹œì‘ ë²„íŠ¼
    st.markdown("<br><br>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ğŸ½ï¸ ì˜¤ëŠ˜ì˜ ì‹ì‚¬ ì…ë ¥í•˜ê¸°", use_container_width=True):
            st.session_state.page = 'chat'
            st.rerun()

# ë©€í‹°í„´ ì±—ë´‡: chat_historyë¥¼ LLM contextë¡œ ë„£ì–´ì¤Œ!
def chat_page():
    st.markdown('<h2 style="text-align: center; color: #2E7D32; margin-bottom: 2rem;">ğŸ’¬ GYM-PTì™€ ëŒ€í™”í•˜ê¸°</h2>', unsafe_allow_html=True)
    col1, col2, col3 = st.columns([1, 6, 1])
    with col1:
        if st.button("â† ë©”ì¸ìœ¼ë¡œ"):
            st.session_state.page = 'main'
            st.rerun()
    chat_container = st.container()
    with chat_container:
        if st.session_state.chat_history:
            for i, (role, content, images) in enumerate(st.session_state.chat_history):
                if role == "user":
                    st.markdown(f"""
                    <div class="chat-message user-message">
                        <strong>ğŸ‘¤ ì‚¬ìš©ì:</strong><br>
                        {content}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="chat-message assistant-message">
                        <strong>ğŸ¤– GYM-PT:</strong><br>
                        {content}
                    </div>
                    """, unsafe_allow_html=True)

    st.markdown("---")
    st.markdown("### ğŸ“ ìƒˆë¡œìš´ ë©”ì‹œì§€")
    uploaded_files = st.file_uploader(
        "ìŒì‹ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš” (ìµœëŒ€ 5ê°œ)",
        type=['png', 'jpg', 'jpeg'],
        accept_multiple_files=True,
        key="uploaded_files",
        help="ì„­ì·¨í•œ ìŒì‹ì˜ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”. ìµœëŒ€ 5ê°œê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ìœ„í•´ í•œ ì‚¬ì§„ì—ëŠ” í•œ ê°€ì§€ ìŒì‹ë§Œ ë‹´ì•„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
    )
    if uploaded_files and len(uploaded_files) > 5:
        st.error("ìµœëŒ€ 5ê°œì˜ ì´ë¯¸ì§€ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        uploaded_files = uploaded_files[:5]
    user_text = st.text_area(
        "ì‹ ì²´ ì •ë³´ì™€ ìŒì‹ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”",
        placeholder="ì˜ˆ: ë‚˜ì´ 25ì„¸, ë‚¨ì„±, í‚¤ 175cm, ëª¸ë¬´ê²Œ 70kg, í‰ì†Œ ìš´ë™ëŸ‰ ì¤‘ê°„, ì•„ì¹¨ì— ì‚¶ì€ ê³„ë€ 2ê°œ ë¨¹ìŒ....",
        height=100,
        key="user_text" 
    )
    col1, col2, col3 = st.columns([1, 1, 1])

    with col2:
        if st.button("ğŸ“¤ ë¶„ì„ ìš”ì²­í•˜ê¸°", use_container_width=True):
            if not uploaded_files and not user_text:
                st.error("ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ëŠ” ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        user_images = []
                        menu_infos = []

                        # ì´ë¯¸ì§€ ì—…ë¡œë“œí•œ ê²½ìš°
                        if uploaded_files:
                            for uploaded_file in uploaded_files:
                                img = Image.open(uploaded_file)
                                user_images.append(img)
                            st.session_state.chat_history.append(("user", user_text, user_images))

                            os.environ.setdefault("OPENAI_API_KEY", "your-api-key-here")
                            inferer = OpenAIInferer("gpt-4o-mini", 0.0)
                            images = [Inferer.to_pil_image(f) for f in uploaded_files]
                            filenames = [f.name for f in uploaded_files]
                            results = inferer(images, filenames)

                            for filename, pred_str in results.items():
                                menu_name, ingredients = parse_prediction(pred_str)
                                rag_context, calorie = get_menu_context_with_threshold(menu_name)
                                menu_infos.append({
                                    "filename": filename,
                                    "menu_name": menu_name,
                                    "calorie": calorie,
                                    "ingredients": ingredients,
                                    "rag_context": rag_context
                                })

                        # í…ìŠ¤íŠ¸ë§Œ ì…ë ¥í•œ ê²½ìš° (ì´ë¯¸ì§€ ì—…ë¡œë“œ ì—†ì„ ë•Œë§Œ ì¶”ê°€)
                        if not uploaded_files and user_text.strip():
                            menu_infos.append({
                                "filename": "-",
                                "menu_name": user_text,
                                "calorie": "",
                                "ingredients": "",
                                "rag_context": ""
                            })

                        # ìµœì¢… ë¶„ì„ (ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ëª¨ë‘ menu_infosì— ë“¤ì–´ê°)
                        final_response = analyze_meal_with_llm(
                            menu_infos=menu_infos,
                            user_info=user_text,
                            chat_history=st.session_state.chat_history
                        )
                        st.session_state.chat_history.append(("assistant", final_response, None))
                        st.rerun()

                    except Exception as e:
                        final_response = f"""
                    ğŸ **ë¶„ì„ ê²°ê³¼ (Demo)**

                    ë“œì‹  ë©”ë‰´ëŠ” ëŒ€ëµ **600kcal** ì •ë„ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.

                    ğŸ“Š **ê¶Œì¥ ì„­ì·¨ëŸ‰ ë¶„ì„:**
                    - ì…ë ¥í•˜ì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ì¼ ê¶Œì¥ ì„­ì·¨ëŸ‰ì€ ì•½ 2,200kcalì…ë‹ˆë‹¤.
                    - í˜„ì¬ ì„­ì·¨ëŸ‰ì„ ì œì™¸í•˜ë©´ ì•½ 1,600kcalê°€ ë‚¨ì•˜ìŠµë‹ˆë‹¤.

                    ğŸƒâ€â™‚ï¸ **ì¹¼ë¡œë¦¬ ì†Œëª¨ ìš´ë™:**
                    - ë¹ ë¥¸ ê±·ê¸°: 90ë¶„ (600kcal ì†Œëª¨)
                    - ìì „ê±° íƒ€ê¸°: 60ë¶„ (600kcal ì†Œëª¨)
                    - ì¡°ê¹…: 45ë¶„ (600kcal ì†Œëª¨)

                    ğŸ¥— **ì¶”ì²œ ì‹ë‹¨:**
                    - ë‹­ê°€ìŠ´ì‚´ ìƒëŸ¬ë“œ (300kcal)
                    - í˜„ë¯¸ë°¥ 1ê³µê¸° (280kcal)
                    - ê³ êµ¬ë§ˆ (200kcal)
                    - ë‘ë¶€ìš”ë¦¬ (150kcal)

                    ê±´ê°•í•œ ì‹ë‹¨ ê´€ë¦¬ë¥¼ ìœ„í•´ ê· í˜•ì¡íŒ ì˜ì–‘ì†Œ ì„­ì·¨ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤! ğŸ’ª

                    *ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.*

                    ---
                    âš ï¸ **ì—ëŸ¬ ë¡œê·¸:**  
                    {str(e)}
                    """
                        st.session_state.chat_history.append(("assistant", final_response, None))
                        st.rerun()
# ë©”ì¸ ì•± ì‹¤í–‰
def main():
    if st.session_state.page == 'main':
        main_page()
    elif st.session_state.page == 'chat':
        chat_page()

if __name__ == "__main__":
    main()
